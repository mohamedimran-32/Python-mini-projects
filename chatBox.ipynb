{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7117dfbd-56cc-4dfc-b3c4-5b6a4b28126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "You said: can you hear me\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "You said: bike bike\n",
      "Listening...\n",
      "You said: goodbye\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n",
      "Google could not understand audio\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sr.Microphone() \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mListening...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     audio = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     10\u001b[39m         filename = \u001b[33m\"\u001b[39m\u001b[33mdrafe.txt\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\voice\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\voice\\Lib\\site-packages\\speech_recognition\\__init__.py:530\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time - phrase_start_time > phrase_time_limit:\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    532\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\voice\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\voice\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "while True:\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "        try:\n",
    "            filename = \"drafe.txt\"\n",
    "            f = open(filename, \"a+\")\n",
    "\n",
    "            recognized_text = r.recognize_google(audio)\n",
    "            print(\"You said:\", recognized_text)\n",
    "\n",
    "            remainder = recognized_text.split()\n",
    "            while remainder:\n",
    "                line, remainder = remainder[:5], remainder[5:]\n",
    "                f.write(' '.join(line) + \"\\n\")\n",
    "\n",
    "            if recognized_text.lower() == 'bye':\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Google error; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5ba81f-2d7f-4635-89a8-1a418d135a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyAudio is working fine!\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "print(\"PyAudio is working fine!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c8b751-1c17-42b3-a426-4c97448dae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Say something...\n",
      "Got it! Recognizing...\n",
      "You said: can you hear me\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"ðŸŽ¤ Say something...\")\n",
    "    audio = r.listen(source)\n",
    "    print(\"Got it! Recognizing...\")\n",
    "\n",
    "try:\n",
    "    text = r.recognize_google(audio)\n",
    "    print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Google Speech Recognition error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa58a4-0e60-4f00-b5ac-7e3e0d6e2376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (voice)",
   "language": "python",
   "name": "voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
